# backend/app/simulation/personas/logic.py

import json
import random  # Adicionar para comportamentos aleatórios
from typing import List, Optional, Tuple, Dict, Any
from langchain_core.messages import (
    SystemMessage,
)
from loguru import logger
from pydantic import ValidationError

from langchain_openai import ChatOpenAI

# REMOVIDO: from trustcall import create_extractor
# REMOVIDO: from app.simulation.schemas.persona_state import ExtractedFact

from app.simulation.schemas.persona import (
    PersonaRead,
    PotentialObjection,
)  # Importar PotentialObjection
from app.simulation.schemas.persona_state import PersonaState
from app.models.simulation.simulation import SimulationOutcomeEnum

# --- Configuração do Persona LLM ---
try:
    # Usar um modelo talvez mais rápido/barato para a persona
    persona_llm = ChatOpenAI(
        model="gpt-4o-mini", temperature=0.6
    )  # Temp um pouco maior para variedade
    logger.info("Persona LLM (gpt-4o-mini) initialized successfully.")
except Exception as e:
    logger.error(f"Failed to initialize Persona LLM: {e}")
    persona_llm = None

# --- Main Logic ---


async def get_next_persona_action(
    persona: PersonaRead,
    ai_response_text: str,
    current_state: PersonaState,  # Mantido por enquanto, pode ser usado para turn_count ou outros estados futuros
    conversation_history: List[
        Dict[str, str]
    ],  # <-- ADICIONADO: Passar histórico recente
) -> Tuple[Optional[str], PersonaState, bool, Optional[SimulationOutcomeEnum]]:
    """
    Determines the persona's next action by prompting an LLM acting as the persona.

    Args:
        persona: The PersonaRead object containing the persona's definition.
        ai_response_text: The last response received from the AI Seller.
        current_state: The current PersonaState object.
        conversation_history: List of recent messages [{'role': 'user'/'assistant', 'content': '...'}].

    Returns:
        A tuple containing:
            - next_persona_message (Optional[str]): The message generated by the Persona LLM.
            - updated_state (PersonaState): The updated state.
            - terminate_simulation (bool): Always False in this version (termination handled by runner).
            - termination_outcome (Optional[SimulationOutcomeEnum]): Always None.
    """
    node_name = f"persona_logic:{persona.persona_id}"
    logger.debug(f"[{node_name}] Determining next action.")
    logger.debug(f"[{node_name}] Last AI response: '{ai_response_text[:100]}...'")

    if not persona_llm:
        logger.error(
            f"[{node_name}] Persona LLM unavailable. Cannot generate response."
        )
        # Retorna erro para o runner tratar
        return None, current_state, True, SimulationOutcomeEnum.SIMULATION_ERROR

    updated_state = current_state.model_copy(deep=True)
    updated_state.turn_count += 1  # Incrementa contador de turno interno (exemplo)

    # --- Construir Prompt REFINADO para o Persona LLM ---

    history_str = "\n".join(
        [f"{msg['role']}: {msg['content']}" for msg in conversation_history[-6:]]
    )
    info_needed_str = (
        ", ".join(
            [
                f"{info['attribute']} sobre {info['entity']}"
                for info in persona.information_needed
            ]
        )
        or "Nenhuma específica"
    )
    # Formatar objeções e interrupções para clareza no prompt
    objections_list_str = (
        "\n".join(
            [
                f"- {obj.objection_text} (Gatilho: {obj.trigger_keyword or obj.trigger_stage or 'Contextual'})"
                for obj in persona.potential_objections
            ]
        )
        or "Nenhuma específica"
    )
    off_topic_list_str = (
        "\n".join([f"- {q}" for q in persona.off_topic_questions])
        or "Nenhuma específica"
    )
    hints_str = ", ".join(persona.behavior_hints) or "Neutro"

    # --- NOVO PROMPT ---
    prompt = f"""
Você está atuando como uma persona de cliente em uma simulação de vendas via WhatsApp. Aja de forma realista e consistente com seu perfil.

**Seu Perfil Detalhado:**
- ID: {persona.persona_id}
- Descrição: {persona.description}
- Seu Objetivo Principal na Conversa: {persona.objective}
- Seu Comportamento Geral (Aja de acordo!): {hints_str}
- Informações que você busca (Contexto): {info_needed_str}
- Objeções que você PODE levantar (Use se natural):
{objections_list_str}
- Perguntas fora de tópico que você PODE fazer (Use raramente, para testar):
{off_topic_list_str}

**Histórico Recente da Conversa:**
{history_str}

**O Agente de Vendas IA acabou de dizer:**
"{ai_response_text}"

**Sua Tarefa:**
Qual a sua **próxima resposta natural e realista**? Siga estas diretrizes:

1.  **Reaja à Resposta do Agente:** Sua resposta deve fazer sentido como continuação direta do que o agente disse.
    *   Se o agente respondeu sua pergunta anterior, reconheça isso (Ex: "Entendi.", "Obrigado pela explicação.").
    *   Se o agente NÃO respondeu sua pergunta (disse "não sei", "contate-nos"), **NÃO ignore**. Reconheça a falta de resposta (Ex: "Ok, entendo que você não tem essa informação agora.").
    *   Se o agente sugeriu uma **alternativa** (teste gratuito, demo, focar em outra funcionalidade), **reaja a essa sugestão** antes de voltar ao seu objetivo principal, *a menos que* seu comportamento seja 'impaciente' ou 'muito direto'. (Ex: "Ok, sobre o teste gratuito, ele tem limite de tempo?" ou "Entendi, mas ainda preciso saber do preço antes de agendar uma demo.").
2.  **Considere Seu Objetivo e Comportamento:**
    *   Mantenha seu `Objetivo Principal` em mente, mas seja flexível. Se a conversa desviar para algo relevante, explore brevemente.
    *   Aja de acordo com seus `Comportamento Geral`. Se for 'cético', questione mais. Se 'impaciente', seja breve e pressione. Se 'detalhista', peça mais especificidade.
3.  **Use Objeções/Interrupções com Moderação:**
    *   Considere levantar uma `potential_objection` se a resposta do agente ou o estágio da conversa tornar isso natural (especialmente se seu comportamento for 'cético' ou 'price_sensitive').
    *   Considere fazer uma `off_topic_question` **raramente**, apenas para simular uma interrupção realista (especialmente se seu comportamento for 'disperso' ou 'curioso').
4.  **Evite Repetição Inútil:** Se o agente já disse que não tem uma informação, evite perguntar exatamente a mesma coisa logo em seguida, a menos que seu comportamento seja 'insistente' ou você queira reformular para obter um detalhe diferente. Tente reagir à alternativa proposta pelo agente primeiro (ver ponto 1).
5.  **Seja Conciso:** Responda como uma pessoa real no WhatsApp.

Gere APENAS a sua próxima mensagem como cliente.
"""
    # --- FIM NOVO PROMPT ---

    # --- Chamar o Persona LLM ---
    try:
        logger.debug(f"[{node_name}] Calling Persona LLM with refined prompt...")
        # Nota: O prompt agora é mais longo e complexo, pode exigir um modelo mais capaz
        # ou mais tempo de resposta dependendo do modelo escolhido em persona_llm.
        response = await persona_llm.ainvoke(prompt)
        next_persona_message = response.content.strip()

        if not next_persona_message:
            # Se o LLM não retornar nada, pode indicar que a persona "desistiu" ou não sabe o que dizer
            logger.warning(
                f"[{node_name}] Persona LLM returned empty response. Ending turn."
            )
            # Tratar como fim natural ou erro? Vamos tratar como fim natural por enquanto.
            return None, updated_state, True, SimulationOutcomeEnum.UNKNOWN

        logger.info(
            f"[{node_name}] Persona LLM generated response: '{next_persona_message[:100]}...'"
        )

        # Lógica de término simplificada (mantida como antes, focada no runner)
        terminate = False
        outcome = None

        return next_persona_message, updated_state, terminate, outcome

    except Exception as e:
        logger.exception(
            f"[{node_name}] Error during Persona LLM call or processing: {e}"
        )
        return None, updated_state, True, SimulationOutcomeEnum.SIMULATION_ERROR
